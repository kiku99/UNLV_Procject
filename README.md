# UNLV_Procject

**Definition of scaleable machine learning for big data**: Big data analytics provides scalable solutions for distributed or very large data. For this project, students will have hands-on experience installing Apache Spark, and practicing python libraries, e.g., MLLib, while applying supervised and unsupervised machine learning algorithms to large datasets for data analysis and developing machine learning models.

## Weekly planâ€¨
- Week 1: Introduction to the project / Study Apache Spark / System setup
- Week 2: Practice Apache Spark libraries
- Week 3: Model training / Model validation / Experiments
- Week 4: Documentation / Presentation / Demo / Wrap-up

## Required skills
- Understanding of MapReduce
- Machine learning
- Fundamental Python skills

## Datasets
- Visual Object Classes Challenge 2012 (VOC2012). Data Source: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/
- Semantics Boundaries Dataset and Benchmark. Data source: http://home.bharathh.info/pubs/codes/SBD/download.html

## Papers
- Scalable machine-learning algorithms for big data analytics: a comprehensive review
- MLlib: Machine Learning in Apache Spark 
- PySpark : High-performance data processing without learning Scala 
- Spark: Cluster Computing with Working Sets 
- Scalable Machine Learning Using PySpark
